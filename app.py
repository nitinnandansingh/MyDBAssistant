import os
from dotenv import load_dotenv
import streamlit as st
import sqlite3

from langchain_community.utilities import SQLDatabase
from langchain_core.messages import AIMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# Load environment variables
load_dotenv()
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")

llm_model = "gemini-1.5-flash"

# ----------------------------
# Utility Functions
# ----------------------------

def init_db(database: str) -> SQLDatabase:
    """
    Connects to a local SQLite database and wraps it in a LangChain SQLDatabase object.

    Args:
        database (str): Path to the SQLite database.

    Returns:
        SQLDatabase: LangChain-compatible SQL database wrapper.
    """
    # Create URI string for SQLite
    db_uri = f"sqlite:///{database}"

    # Construct a SQLAlchemy engine from URI, connect to DB, wrap in LangChain object
    return SQLDatabase.from_uri(db_uri)

def fetch_table_info(database: str) -> dict:
    """
    Retrieves schema information (tables and columns) from the given SQLite database.

    Args:
        database (str): Path to the SQLite database.

    Returns:
        dict: Mapping of table names to column lists.
    """
    conn = sqlite3.connect(database)
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
    tables = cursor.fetchall()
    
    table_info = {}
    for (table_name,) in tables:
        cursor.execute(f"PRAGMA table_info({table_name});")
        columns = cursor.fetchall()
        column_names = [col[1] for col in columns]
        table_info[table_name] = column_names

    conn.close()
    return table_info

# ----------------------------
# Chain Construction
# ----------------------------

def get_sql_chain(db: SQLDatabase, model: str):
    """
    Creates a chain to generate SQL queries based on user questions and table schema.

    Args:
        db (SQLDatabase): LangChain SQL database object.
        model (str): Model name to use for query generation.

    Returns:
        Runnable: LangChain chain that outputs SQL query string.
    """
    template = """
    You are a data analyst at a company. You are interacting with a user who is asking you questions about the company's database.
    Based on the table schema below, write a SQL query that would answer the user's question. Take the conversation history into account.

    <SCHEMA>{schema}</SCHEMA>

    Conversation History: {chat_history}
    
    Write only the SQL query and nothing else. Do not wrap the SQL query in any other text, not even backticks.

    Question: {question}
    SQL Query:
    """
    prompt = ChatPromptTemplate.from_template(template)

    if model == llm_model:
        llm = ChatGoogleGenerativeAI(model=llm_model, api_key=GOOGLE_API_KEY)

    def get_schema(_):
        return db.get_table_info()

    return (
        RunnablePassthrough.assign(schema=get_schema)
        | prompt
        | llm
        | StrOutputParser()
    )

def get_response(user_query: str, db: SQLDatabase, chat_history: list, model: str):
    """
    Full pipeline to generate natural language responses from user queries and database content.

    Args:
        user_query (str): User input string.
        db (SQLDatabase): Connected database.
        chat_history (list): List of past messages.
        model (str): Model name to use.

    Returns:
        str: Natural language response generated by the model.
    """
    sql_chain = get_sql_chain(db, model)

    template = """
    You are a data analyst at a company. You are interacting with a user who is asking you questions about the company's database.
    Based on the table schema below, question, sql query, and sql response, write a natural language response.

    <SCHEMA>{schema}</SCHEMA>
    
    Conversation History: {chat_history}
    SQL Query: <SQL>{query}</SQL>
    User question: {question}
    SQL Response: {response}
    """
    prompt = ChatPromptTemplate.from_template(template)

    if model == llm_model:
        llm = ChatGoogleGenerativeAI(model=llm_model, api_key=GOOGLE_API_KEY)

    chain = (
        RunnablePassthrough.assign(query=sql_chain).assign(
            schema=lambda _: db.get_table_info(),
            response=lambda vars: db.run(vars["query"])
        )
        | prompt
        | llm
        | StrOutputParser()
    )

    return chain.invoke({
        "question": user_query,
        "chat_history": chat_history
    })

# ----------------------------
# Streamlit App Interface
# ----------------------------

# Page settings
st.set_page_config(page_title="Chat with DB", page_icon=":speech_balloon")
st.title("My DB Assistant :speech_balloon:")

# Session state initialization
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        AIMessage(content="Hello! I am a database assistant. Ask me anything about your database.")
    ]
if "db_connected" not in st.session_state:
    st.session_state.db_connected = False
if "table_info" not in st.session_state:
    st.session_state.table_info = {}

# Sidebar
with st.sidebar:
    st.subheader("Settings")
    st.write("Connect to a local SQLite DB and start chatting with it using natural language.")

    model = st.radio("Model", [llm_model])
    st.session_state.model = model

    db_name = st.text_input("Database", value="mydatabase.db", key="Database")

    button_text = "Disconnect" if st.session_state.db_connected else "Connect"

    if st.button(button_text):
        if st.session_state.db_connected:
            st.session_state.db_connected = False
            st.session_state.table_info = {}
            st.session_state.db = None
            st.success("Disconnected from the database.")
        else:
            with st.spinner("Connecting to the database..."):
                try:
                    db = init_db(db_name)
                    st.session_state.db = db
                    st.session_state.db_connected = True
                    st.session_state.table_info = fetch_table_info(db_name)
                    st.success("Connected to the database!")
                except Exception as e:
                    st.session_state.db_connected = False
                    st.error(f"Failed to connect: {e}")

    if st.session_state.db_connected:
        st.subheader("Tables and Columns")
        for table, columns in st.session_state.table_info.items():
            with st.expander(f"**Table:** {table}"):
                for column in columns:
                    st.write(f"\U0001F3F7Ô∏è {column}")

# Chat interface
for message in st.session_state.chat_history:
    with st.chat_message("AI" if isinstance(message, AIMessage) else "Human"):
        st.markdown(message.content)

# Input + Response Handling
if st.session_state.db_connected:
    user_query = st.chat_input("Type a message...")
    if user_query and user_query.strip():
        st.session_state.chat_history.append(HumanMessage(content=user_query))
        with st.chat_message("Human"):
            st.markdown(user_query)

        with st.chat_message("AI"):
            model = st.session_state.model
            response = get_response(user_query, st.session_state.db, st.session_state.chat_history, model)
            st.markdown(response)
        st.session_state.chat_history.append(AIMessage(content=response))
else:
    st.info("Connect to the database to chat.")
